{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{1: [{'count': 6, 'pattern': [1]},\n",
       "  {'count': 7, 'pattern': [2]},\n",
       "  {'count': 6, 'pattern': [3]},\n",
       "  {'count': 2, 'pattern': [4]},\n",
       "  {'count': 2, 'pattern': [5]}],\n",
       " 2: [{'count': 4, 'pattern': [1, 2]},\n",
       "  {'count': 4, 'pattern': [1, 3]},\n",
       "  {'count': 2, 'pattern': [1, 5]},\n",
       "  {'count': 4, 'pattern': [2, 3]},\n",
       "  {'count': 2, 'pattern': [2, 4]},\n",
       "  {'count': 2, 'pattern': [2, 5]}],\n",
       " 3: [{'count': 2, 'pattern': [1, 2, 5]}]}"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#!/usr/bin/env python3\n",
    "# -*- coding: utf-8 -*-\n",
    "\"\"\"\n",
    "Created December 2018\n",
    "\n",
    "@author: ebecerra\n",
    "\"\"\"\n",
    "\n",
    "# Emanuel Becerra Soto\n",
    "# MD01 CIC IPN\n",
    "\n",
    "# Algorithm Direct Hashing and Pruning\n",
    " \n",
    "######### Libraries #########\n",
    "\n",
    "import itertools\n",
    "\n",
    "######### Functions #########\n",
    "\n",
    "# Flattens a list\n",
    "def flatten(l):\n",
    "    return list( itertools.chain.from_iterable( l ) )\n",
    "\n",
    "# Finds the itemset of a database\n",
    "def single_items(database):\n",
    "    item_union = set()\n",
    "    candidates_1k = []\n",
    "    for transaction in database:\n",
    "        x = set(transaction)\n",
    "        item_union = item_union | x\n",
    "    for item in item_union:\n",
    "        candidates_1k.append([item])\n",
    "    return candidates_1k\n",
    "\n",
    "# Check for a correct value of the minimu support\n",
    "def check_min_sup( data_base, min_sup ):\n",
    "    n_tran = len(data_base)\n",
    "    if isinstance(min_sup, float) and min_sup <= 1 and min_sup >= 0:\n",
    "        cut_off = min_sup * n_tran\n",
    "    elif isinstance(min_sup, int) and min_sup >= 1:\n",
    "        cut_off = min_sup\n",
    "    else:\n",
    "        exit('Error: min_sup must be between 0.0 and 1.0 or a positive integer')\n",
    "    return cut_off\n",
    "\n",
    "# Performs the join operation over candidate item sets  \n",
    "def join(pattern1, pattern2):\n",
    "    k = len(pattern1)\n",
    "    candidate_k1 = []        \n",
    "    for idx in range(k):\n",
    "        if pattern1[idx] == pattern2[idx] and idx + 1 < k:\n",
    "            candidate_k1.append(pattern1[idx])\n",
    "        # The less than equal comparission preserves the\n",
    "        # lexicographic order\n",
    "        elif pattern1[idx] < pattern2[idx] and idx + 1 == k:\n",
    "            candidate_k1.append(pattern1[idx])\n",
    "            candidate_k1.append(pattern2[idx])\n",
    "        else:\n",
    "            candidate_k1 = []\n",
    "            break\n",
    "    return candidate_k1\n",
    "\n",
    "# Generates candidate using a hash table\n",
    "def gen_candidates( freqs, hash_table, cut_off_int ):\n",
    "    table_size = len(hash_table)\n",
    "    Ck=[]\n",
    "    all_2_groups_freq = list( itertools.combinations( freqs, 2) )\n",
    "    for group in all_2_groups_freq:\n",
    "        group = list(group)\n",
    "        cki = join( group[0], group[1] )\n",
    "        idx = hash( str(cki) ) % table_size\n",
    "        if hash_table[ idx ] >= cut_off_int:\n",
    "            Ck.append( cki )\n",
    "    return Ck\n",
    "\n",
    "# Extracts the frequent itemsets of 1 element\n",
    "def part_1( data_base, min_sup, items, table_size ):\n",
    "    cut_off = check_min_sup( data_base, min_sup )\n",
    "    ######  DHP ######\n",
    "    size_2_subsets = list( itertools.combinations( flatten(items), 2) )\n",
    "    # Initialization of hash table\n",
    "    hash_table_2 = [0] * table_size\n",
    "    # Initialization of dictonary of counts\n",
    "    COUNTS = {}\n",
    "    for item in items:\n",
    "        COUNTS[ str(item) ] = { 'count': 0, 'pattern': item }\n",
    "    for transaction in data_base:\n",
    "        for item in items:\n",
    "            if set(item) <= set(transaction):\n",
    "                COUNTS[ str(item) ]['count'] += 1\n",
    "        for subset_size_2 in size_2_subsets:\n",
    "            subset_size_2 = list(subset_size_2)\n",
    "            if set(subset_size_2) <= set(transaction):\n",
    "                # hashing the subset of size 2\n",
    "                # and then taking the modulo to see its position on the table\n",
    "                idx = hash(str(subset_size_2)) % table_size\n",
    "                # Adding 1 to the hash table\n",
    "                hash_table_2[ idx ] += 1\n",
    "    frequent_size_1 = []\n",
    "    for key in COUNTS:\n",
    "        if COUNTS[key]['count'] >= cut_off:\n",
    "            frequent_size_1.append( COUNTS[key] )\n",
    "    return { 'freq': frequent_size_1, 'hash_table': hash_table_2 } \n",
    "\n",
    "# Extracts the frequent itemsets of k element        \n",
    "def part_2( data_base, min_sup, items, freqs_1k, hash_table_2 ):\n",
    "    table_size = len(hash_table_2)\n",
    "    cut_off = check_min_sup( data_base, min_sup )\n",
    "    RESULTS = {}\n",
    "    k = 3\n",
    "    Ck = ['Initialization']\n",
    "    freqs = freqs_1k\n",
    "    hash_table = hash_table_2\n",
    "    while Ck: # Candidate Set is not Empty\n",
    "        Ck = gen_candidates( freqs, hash_table, cut_off )\n",
    "        # Initialization of the count dictionary\n",
    "        COUNTS = {}\n",
    "        # Initialization of the COUNTS dictionary\n",
    "        for cki in Ck:\n",
    "            COUNTS[ str(cki) ] = { 'count': 0, 'pattern': cki }\n",
    "        hash_table_k = [0] * table_size\n",
    "        size_k_subsets = list( itertools.combinations( freqs, k) )\n",
    "        for transaction in data_base:\n",
    "            # Counting\n",
    "            for candidate in Ck:\n",
    "                if set( candidate ) <= set(transaction):\n",
    "                    COUNTS[ str(candidate) ]['count'] += 1\n",
    "            # Hash Table building\n",
    "            for subset_size_k in size_k_subsets:\n",
    "                subset_size_k = flatten(list(subset_size_k))\n",
    "                if set(subset_size_k) <= set(transaction):\n",
    "                    # hashing the subset of size k\n",
    "                    # and then taking the modulo to see its position on the table\n",
    "                    idx = hash( str(subset_size_k) ) % table_size\n",
    "                    # Adding 1 to the hash table\n",
    "                    hash_table_k[ idx ] += 1\n",
    "        # Getting the frequent patterns\n",
    "        frequent_detail = []\n",
    "        for key in COUNTS:\n",
    "            if COUNTS[key]['count'] >= cut_off:\n",
    "                frequent_detail.append( COUNTS[key] )\n",
    "        if frequent_detail:\n",
    "            RESULTS[ k-1 ] = frequent_detail        \n",
    "        # Increasing for the next iteration\n",
    "        k += 1  \n",
    "        # Generating freq for next iteration\n",
    "        freqs = []\n",
    "        for freq_i in frequent_detail:\n",
    "            freqs.append( freq_i['pattern'] )\n",
    "    return RESULTS\n",
    "    \n",
    "######### Main Program #########\n",
    "\n",
    "# The transactions must be in a lexicographic order\n",
    "\n",
    "D = [\n",
    "     [1,2,5],\n",
    "     [2,4],\n",
    "     [2,3],\n",
    "     [1,2,4],\n",
    "     [1,3],\n",
    "     [2,3],\n",
    "     [1,3],\n",
    "     [1,2,3,5],\n",
    "     [1,2,3],\n",
    "     ]\n",
    "\n",
    "def main( data_base, min_sup, table_size ):\n",
    "    items = single_items(data_base)\n",
    "    part_1_out = part_1(data_base, min_sup, items, table_size)\n",
    "    freqs_1k = []\n",
    "    for freq_i in part_1_out['freq']:\n",
    "        freqs_1k.append( freq_i['pattern'] )\n",
    "    results = part_2( data_base, min_sup, items,\n",
    "                     freqs_1k, part_1_out['hash_table'] )\n",
    "    results[1] = part_1_out['freq']\n",
    "    return results\n",
    "\n",
    "main( D, 2/9, 30 )  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
